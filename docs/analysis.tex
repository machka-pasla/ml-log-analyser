\documentclass[14pt,a4paper]{extarticle}

\usepackage{fontspec}
\setmainfont{Times New Roman}
\setmonofont{Times New Roman}
\usepackage{polyglossia}
\setmainlanguage{russian}
\newfontfamily\cyrillicfonttt{Times New Roman}
\usepackage{geometry}
\geometry{left=30mm,right=10mm,top=20mm,bottom=20mm}
\usepackage{setspace}
\onehalfspacing
\usepackage{indentfirst}
\setlength{\parindent}{1.25cm}
\usepackage{graphicx}
\graphicspath{{docs/figures/}}
\usepackage{svg}
\svgpath{{docs/figures/}}
\svgsetup{inkscapelatex=false, inkscapeexe={scripts/inkscape-wrapper.sh}, inkscapeversion=1}
\usepackage{longtable}
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\usepackage{hyperref}
\hypersetup{hidelinks}

\begin{document}

\begin{titlepage}
    \begin{center}
        ГАОУ ДПО ЦПМ\\[40mm]
        \textbf{Проект}\\[4mm]
        \textbf{«Анализатор логов на основе ИИ»}\\[30mm]
        \begin{flushleft}
            \hspace*{80mm}Подъяпольский\\
            \hspace*{80mm}Ярослав Васильевич
        \end{flushleft}
        \vfill
        Москва 2026
    \end{center}
\end{titlepage}

\tableofcontents
\newpage

\addcontentsline{toc}{section}{Термины и определения}
\section*{Термины и определения}
\begin{longtable}{|L{4.5cm}|L{9.5cm}|}
\hline
\textbf{Термин} & \textbf{Описание} \\ \hline
\endfirsthead
\hline
\textbf{Термин} & \textbf{Описание} \\ \hline
\endhead
Лог & Запись о событии в системе, сформированная приложением или компонентом инфраструктуры. \\ \hline
Событие & Агрегированная запись с временной меткой, источником и сообщением. \\ \hline
Аномалия & Отклонение от типичного поведения, выявляемое по статистике или признакам. \\ \hline
Anomaly score & Числовая оценка степени аномальности события. \\ \hline
Нормализация логов & Приведение записей к единой схеме и формату данных. \\ \hline
Концепт-дрифт & Изменение характеристик «нормы» поведения во времени. \\ \hline
\caption{Термины и определения}
\label{tab:terms}
\end{longtable}
\newpage

\addcontentsline{toc}{section}{Перечень сокращений и обозначений}
\section*{Перечень сокращений и обозначений}
\begin{longtable}{|L{3.8cm}|L{10.2cm}|}
\hline
\textbf{Сокращение} & \textbf{Расшифровка} \\ \hline
\endfirsthead
\hline
\textbf{Сокращение} & \textbf{Расшифровка} \\ \hline
\endhead
SIEM & Система управления событиями безопасности и корреляции логов. \\ \hline
UEBA & Поведенческая аналитика пользователей и сущностей. \\ \hline
ML & Машинное обучение. \\ \hline
KPI & Ключевые показатели эффективности. \\ \hline
ECS & Elastic Common Schema для нормализации логов\cite{ecs}. \\ \hline
OpenTelemetry & Стандарт телеметрии, включая логирование\cite{otel_logs}. \\ \hline
ATT\&CK & База знаний техник и тактик атак\cite{mitre}. \\ \hline
API & Программный интерфейс взаимодействия сервисов. \\ \hline
\caption{Сокращения и обозначения}
\label{tab:abbr}
\end{longtable}
\newpage

\addcontentsline{toc}{section}{Введение}
\section*{Введение}
Проект посвящён разработке учебного анализатора логов на основе методов машинного обучения. Целью является демонстрация полного цикла: приём и нормализация логов, извлечение признаков, обучение модели, выявление аномалий и визуализация результатов. Подход позволяет показать, как поток событий преобразуется в управляемый список подозрительных случаев и как на практике строится воспроизводимый контур мониторинга и реагирования.
\newpage

\section{Исследование проблемы}

\subsection{Описание проблемы}
Современные ИТ-инфраструктуры генерируют большие объёмы логов: события приложений, системные журналы, сетевые срабатывания, аудит пользователей. Потоки событий быстро достигают миллионов строк в сутки и включают разнообразные форматы, уровни критичности и семантики. Анализ таких потоков вручную или исключительно на основе статических правил перестаёт масштабироваться.

Существенная часть угроз проявляется через слабые сигналы: необычные последовательности действий, редкие коды ошибок, нетипичные адреса и параметры запросов. Эти сигналы могут быть размыты на фоне нормальной активности и не описываются заранее подготовленными сигнатурами. В результате возрастает риск позднего обнаружения атак и повышается нагрузка на аналитиков.

\subsection{Актуальность}
По данным отраслевых обзоров, задержки в обнаружении инцидентов по-прежнему составляют дни и недели\cite{verizon,mandiant,enisa}. Автоматизация первичного анализа с применением методов машинного обучения позволяет выявлять статистические отклонения и дополнять правила корреляции в SIEM. Для подразделений мониторинга и реагирования это означает сокращение времени реакции и снижение числа пропущенных инцидентов\cite{verizon,mandiant}.

Дополнительной мотивацией является потребность в воспроизводимых учебных проектах: учащимся важно видеть полный цикл обработки логов --- от генерации данных до визуализации результатов, при этом иметь возможность повторить эксперимент в лабораторной среде.

\subsection{Ключевые тезисы (презентационный формат)}
\begin{itemize}
    \item Логи --- основной слой телеметрии для выявления инцидентов и расследований\cite{nistlog}.
    \item Реальное время обнаружения измеряется днями и неделями, что требует автоматизации первичного анализа\cite{verizon,mandiant,enisa}.
    \item ML-методы дополняют правила и сигнатуры, повышая чувствительность к неизвестным сценариям\cite{loganomaly,logbert}.
    \item Единая схема логов повышает сопоставимость данных и качество аналитики\cite{ecs,otel_logs}.
    \item Контур обучения и переобучения необходим для устойчивости к концепт-дрифту\cite{nist_iscm}.
    \item Учебный стенд должен быть воспроизводимым, прозрачным и простым в разворачивании.
\end{itemize}

\subsection{Анализ аналогов}
Коммерческие платформы SIEM/UEBA объединяют нормализацию логов, корреляцию событий и поведенческую аналитику. Их преимущества --- зрелые интеграции и масштабирование, но для учебных целей они часто недоступны из-за стоимости, закрытых алгоритмов и требований к инфраструктуре.

Существуют и open-source решения, однако они либо ориентированы на агрегацию и поиск, либо требуют существенной настройки. Нужен демонстрационный проект с прозрачным ML-ядром и контролируемыми входными данными, чтобы показать принципы обнаружения аномалий в логах\cite{nistlog}.

\subsection{Стейкхолдеры и ожидаемый эффект}
Система ориентирована на образовательные и демонстрационные сценарии, но отражает задачи реальной эксплуатации. Ожидаемые эффекты для ключевых ролей представлены в таблице~\ref{tab:stakeholders}.

\begin{longtable}{|L{4.8cm}|L{9.2cm}|}
\hline
\textbf{Стейкхолдер} & \textbf{Ожидания и эффект} \\ \hline
\endfirsthead
\hline
\textbf{Стейкхолдер} & \textbf{Ожидания и эффект} \\ \hline
\endhead
Аналитики безопасности & Сокращение времени первичного разбора, приоритизация инцидентов, снижение пропусков. \\ \hline
Администраторы и DevOps & Понимание качества логирования, быстрый поиск нетипичных ошибок после релизов. \\ \hline
Руководство & Метрики эффективности контроля, прозрачность процессов и воспроизводимость результатов. \\ \hline
Обучающиеся & Практический опыт полного ML-пайплайна и анализа логов на контролируемых данных. \\ \hline
\caption{Стейкхолдеры и ожидаемые эффекты}
\label{tab:stakeholders}
\end{longtable}

\subsection{Нормативные и организационные требования}
Рекомендации по построению непрерывного мониторинга и управлению журналами подчёркивают необходимость централизованного сбора, нормализации и использования логов для аналитики\cite{nistlog,nist_iscm,cisa_logging,owasp_logging}. Практики безопасной эксплуатации также опираются на наличие корректного аудита, контроля и процедур реагирования\cite{nist_sp80053,nist_csf,nist_idps}.

В прикладном аспекте для учебного проекта важно показать, как требования к логированию реализуются в системе: от обязательных полей до единых схем данных. Такие требования закреплены и в прикладных рекомендациях по безопасности и контролям, где логирование рассматривается как базовый механизм обнаружения инцидентов\cite{cis_controls}.

\subsection{Источники и форматы логов}
Источники логов включают журналы приложений, операционных систем, средств защиты и сетевых устройств. Форматы варьируются от структурированных JSON-объектов до свободного текста. Для сопоставимости данных используются схемы нормализации, например Elastic Common Schema или модели данных OpenTelemetry\cite{ecs,otel_logs}. Это повышает качество последующего анализа и упрощает интеграцию с внешними инструментами.

\subsection{Типовые источники логов и ценность}
В таблице~\ref{tab:sources} показаны ключевые источники логов и их аналитическая ценность в контексте обнаружения аномалий.

\begin{longtable}{|L{4.5cm}|L{4.8cm}|L{5.2cm}|}
\hline
\textbf{Источник} & \textbf{Примеры событий} & \textbf{Ценность для анализа} \\ \hline
\endfirsthead
\hline
\textbf{Источник} & \textbf{Примеры событий} & \textbf{Ценность для анализа} \\ \hline
\endhead
Приложения & Ошибки 4xx/5xx, таймауты, исключения & Раннее выявление дефектов и атак на приложения. \\ \hline
ОС и хосты & Авторизация, запуск процессов, системные ошибки & Контроль доступа, выявление нетипичных действий. \\ \hline
Сетевые устройства & Блокировки, ACL, соединения & Анализ внешней активности и аномалий трафика. \\ \hline
Средства защиты & IDS/IPS, EDR, AV & Корреляция с телеметрией безопасности. \\ \hline
Инфраструктурные сервисы & БД, брокеры, очереди & Поиск деградаций и всплесков нагрузки. \\ \hline
\caption{Типовые источники логов и ценность}
\label{tab:sources}
\end{longtable}

\subsection{Обзор научных подходов}
Научные работы по анализу логов включают две ключевые ветви: парсинг и обнаружение аномалий. Для парсинга часто используются алгоритмы шаблонного выделения, среди которых известны методы с фиксированной глубиной дерева и иерархической кластеризацией; обзор и бенчмарки представлены в работах по автоматизированному парсингу\cite{logbench}.

Для обнаружения аномалий применяются как статистические подходы, так и нейросетевые модели. Среди современных решений --- последовательностные модели и трансформеры, которые выявляют нетипичные паттерны в последовательностях событий\cite{loganomaly,logbert}. Эти работы демонстрируют потенциал ML-подходов для поиска редких сценариев, но требуют больших данных и вычислительных ресурсов. В учебном проекте целесообразно сочетать базовый частотный метод и простую ML-модель, чтобы показать разницу подходов без усложнения инфраструктуры.

Для практического прототипирования доступны открытые инструменты и наборы экспериментов, например библиотека Loglizer, где собраны примеры классических алгоритмов и датасеты логов\cite{loglizer}.

\subsection{Особенности проблематики}
Логи разнородны по источникам и форматам: JSON Lines, plain text, полу-структурированные сообщения. В реальных системах возможны пропуски полей, различная точность времени, а также наличие ложных срабатываний. Это требует аккуратной валидации и устойчивого извлечения признаков.

Дополнительно необходимо учитывать концепт-дрифт --- постепенное изменение «нормального» поведения. Поэтому система должна поддерживать периодическое переобучение и сохранение артефактов модели для воспроизводимости. Также важно учитывать типовые сценарии атак, описанные в MITRE ATT\&CK, чтобы корректно интерпретировать найденные отклонения\cite{mitre}.

\subsection{Карта угроз и наблюдаемых сигналов}
В таблице~\ref{tab:signals} приведены типовые угрозы и сигналы в логах, которые могут быть выявлены за счёт аномалий.

\begin{longtable}{|L{4.6cm}|L{6cm}|L{4.4cm}|}
\hline
\textbf{Сценарий} & \textbf{Сигналы в логах} & \textbf{Почему аномалия} \\ \hline
\endfirsthead
\hline
\textbf{Сценарий} & \textbf{Сигналы в логах} & \textbf{Почему аномалия} \\ \hline
\endhead
Brute-force & Серии failed/denied, частые попытки входа & Резкое увеличение частот шаблонов. \\ \hline
Credential stuffing & Много учётных записей с одного источника & Нетипичные комбинации user/IP. \\ \hline
Эксплуатация уязвимости & Всплеск 5xx, новые сообщения об ошибках & Новые/редкие шаблоны. \\ \hline
Латеральное перемещение & Обращения к множеству хостов за короткий период & Изменение распределений по источникам. \\ \hline
Экфильтрация & Нестандартные объёмы и направления обмена & Аномальные размеры и временные паттерны. \\ \hline
Внутренние злоупотребления & Доступы ночью, нетипичные действия аккаунта & Сдвиг временных признаков и паттернов. \\ \hline
\caption{Карта угроз и сигналов}
\label{tab:signals}
\end{longtable}

\subsection{Цель и задачи проекта}
\textbf{Цель:} разработать учебный анализатор логов, демонстрирующий подходы выявления аномалий в задачах мониторинга безопасности.

\textbf{Задачи:}
\begin{enumerate}
    \item Реализовать приём логов в двух форматах и валидацию обязательных полей.
    \item Построить модуль извлечения признаков и два детектора аномалий.
    \item Обеспечить хранение событий и результатов анализа.
    \item Предоставить API и дашборд для просмотра метрик и аномалий.
    \item Подготовить сценарий демонстрации и документацию.
\end{enumerate}

\textbf{Ожидаемые результаты:}
\begin{itemize}
    \item воспроизводимый учебный стенд, разворачиваемый одной командой;
    \item демонстрация различий между базовым и ML-подходами к детекции;
    \item прозрачные метрики и артефакты обучения для повторяемости эксперимента;
    \item набор сценариев с контролируемыми аномалиями для обучения и презентаций.
\end{itemize}

\section{Решение проблемы}

\subsection{Техническое задание}
В рамках проекта реализуется система с поддержкой форматов JSON Lines и plain text. Обязательные поля: timestamp, host или service, level, message. Опциональные: user, ip, request\_id и произвольные атрибуты. Для детектирования аномалий используются базовый частотный метод и ML-подход (Isolation Forest). Результаты сохраняются в базе данных, доступны через REST API и визуализируются в дашборде.

\subsection{Ключевые преимущества решения}
Решение спроектировано как демонстрационный стенд, который при этом сохраняет инженерную дисциплину. Ключевые преимущества:
\begin{itemize}
    \item прозрачность: понятный пайплайн и интерпретируемые признаки;
    \item воспроизводимость: артефакты обучения и версия модели сохраняются;
    \item расширяемость: новые источники логов и модели подключаются через интерфейсы;
    \item автономность: генератор синтетики позволяет проверять сценарии без внешних данных;
    \item интеграция: метрики доступны через API и совместимы с Grafana.
\end{itemize}

\subsection{Требования к данным и качеству}
События должны быть упорядочены во времени, иметь корректный формат дат, единый часовой пояс и понятные уровни логирования. При отсутствии необязательных полей система должна корректно работать, используя нулевые или булевые индикаторы. Для корректной работы модели необходим репрезентативный «нормальный» поток логов.

\subsection{Контур качества данных}
Для надёжной детекции важна устойчивость входного потока. На уровне входа контролируются:
\begin{itemize}
    \item наличие обязательных полей и валидность временных меток;
    \item корректность уровней логирования и источников;
    \item отбраковка строк, не соответствующих шаблонам парсинга;
    \item нормализация текстов сообщений (маскирование чисел, UUID, IP);
    \item контроль объёма атрибутов, чтобы не допустить «шумных» событий.
\end{itemize}
Такой контур снижает загрязнение данных, уменьшает шум и повышает стабильность метрик.

\subsection{Архитектура и компоненты}
Архитектура построена по слоям domain / application / infrastructure. Доменный слой описывает сущности, прикладной --- правила обработки, инфраструктурный --- хранение, API и запуск. Такая структура обеспечивает расширяемость и тестируемость.

\begin{figure}[h]
    \centering
\includesvg[width=0.95\textwidth]{architecture}
    \caption{Слойная архитектура решения}
\end{figure}

\subsection{Пайплайн обработки}
Пайплайн включает приём логов, парсинг, извлечение признаков, инференс модели, сохранение результатов и отдачу метрик. Такой процесс отражён на рисунке~\ref{fig:pipeline}.

\begin{figure}[h]
    \centering
\includesvg[width=\textwidth]{pipeline}
    \caption{Пайплайн обработки событий}
    \label{fig:pipeline}
\end{figure}

\subsection{Жизненный цикл модели}
Жизненный цикл включает сбор данных, обучение, инференс и переобучение. Такая структура позволяет поддерживать актуальность модели при изменении «нормы» поведения.

\begin{figure}[h]
    \centering
\includesvg[width=\textwidth]{lifecycle}
    \caption{Жизненный цикл модели и данных}
\end{figure}

\subsection{Как работает система}
Работа системы строится как последовательная обработка событий от приёма до выдачи метрик. На входе принимаются строки логов, которые приводятся к единой модели данных, а затем анализируются двумя детекторами аномалий.

Обобщённый алгоритм работы включает следующие шаги:
\begin{enumerate}
    \item Приём логов в формате JSON Lines или plain text через API или файл.
    \item Парсинг и проверка обязательных полей: время, источник, уровень, сообщение.
    \item Извлечение признаков и формирование числового вектора события.
    \item Расчёт anomaly score выбранной моделью и сравнение с порогом.
    \item Сохранение результата вместе с модельной версией в базе данных.
    \item Обновление агрегированных метрик и отображение в дашборде.
\end{enumerate}

Роли ключевых модулей:
\begin{itemize}
    \item Ingest: принимает поток, валидирует формат и распределяет по парсерам.
    \item Parsing: приводит события к единой схеме и извлекает базовый контекст.
    \item Features: формирует числовой вектор для моделей.
    \item Model: рассчитывает score и возвращает метку.
    \item Storage: хранит события, результаты и артефакты обучения.
    \item API/Dashboard: предоставляет доступ к аномалиям и метрикам.
\end{itemize}

На этапе парсинга система приводит события к единой схеме, что упрощает дальнейший анализ. Для JSON Lines используется прямое чтение ключей, а для plain text применяется набор регулярных шаблонов, позволяющих выделить timestamp, уровень и источник. Дополнительные атрибуты (user, ip, request\_id) извлекаются из текста сообщения. Если строка не соответствует шаблону, она отклоняется, что снижает риск загрязнения данных.

Хранение результатов построено так, чтобы обеспечивать трассируемость: вместе с событием записывается score, метка и версия модели. Метрики (общее число событий, доля аномалий, время последней загрузки) рассчитываются на основе базы данных и доступны как через API, так и в Grafana. Артефакты обучения сохраняются в реестр, что позволяет вернуться к любому состоянию модели и повторить эксперимент.
Базовый частотный метод хорошо улавливает появление новых шаблонов сообщений, тогда как Isolation Forest фиксирует нетипичные комбинации параметров (уровень, длина текста, временные признаки). Это позволяет находить аномалии как по новизне шаблона, так и по атипичным сочетаниям признаков даже при знакомом сообщении.

\subsection{Извлечение признаков}
Для каждого события формируется числовой вектор признаков. В таблице~\ref{tab:features} приведён перечень основных признаков.

\begin{longtable}{|L{4.8cm}|L{9.6cm}|}
\hline
\textbf{Признак} & \textbf{Описание} \\ \hline
\endfirsthead
\hline
\textbf{Признак} & \textbf{Описание} \\ \hline
\endhead
Уровень события & Код уровня (DEBUG/INFO/WARNING/ERROR и т.д.). \\ \hline
Длина сообщения & Количество символов. \\ \hline
Слова и уникальность & Число слов и доля уникальных слов. \\ \hline
Цифры и спецсимволы & Количество цифр и специальных символов. \\ \hline
Наличие IP и счётчик IP & Флаг и количество IP-адресов в сообщении. \\ \hline
Временные признаки & Час, день недели, синусы/косинусы времени. \\ \hline
Наличие пользователя и длина & Флаг пользователя и длина строки user. \\ \hline
Наличие request\_id & Флаг и длина request\_id. \\ \hline
Хэш источника & Нормализованный хэш host/service. \\ \hline
Хэш шаблона & Хэш нормализованного шаблона сообщения. \\ \hline
\caption{Перечень признаков}
\label{tab:features}
\end{longtable}

\subsection{Модели обнаружения}
Базовый детектор использует частоту нормализованных шаблонов сообщений. ML-детектор основан на Isolation Forest и анализирует числовые признаки. Для каждого события вычисляется score и формируется решение normal/anomaly. Такой подход соответствует требованиям демонстрационного проекта: прозрачность и воспроизводимость.

\subsection{Сравнение подходов}
Сравнение базового метода и ML-детектора приведено в таблице~\ref{tab:methods}.

\begin{longtable}{|L{4.5cm}|L{5.25cm}|L{5.25cm}|}
\hline
\textbf{Критерий} & \textbf{Базовый метод} & \textbf{ML-метод} \\ \hline
\endfirsthead
\hline
\textbf{Критерий} & \textbf{Базовый метод} & \textbf{ML-метод} \\ \hline
\endhead
Интерпретация & Прозрачные частоты шаблонов & Более сложное объяснение, но богаче признаки \\ \hline
Чувствительность & Высока к новым шаблонам & Высока к сложным сочетаниям признаков \\ \hline
Требования к данным & Минимальные & Требуется стабильный набор признаков \\ \hline
Скорость обучения & Очень высокая & Выше вычислительные затраты \\ \hline
Устойчивость к шуму & Средняя & Выше при хорошей нормализации \\ \hline
\caption{Сравнение подходов детекции}
\label{tab:methods}
\end{longtable}

\subsection{Пороговая настройка и переобучение}
Порог аномальности подбирается эмпирически на синтетических данных. Периодическое переобучение реализуется батчами: модель обучается на новом нормальном потоке, а артефакты сохраняются в реестр. Это позволяет отслеживать версии модели и проводить регрессионную проверку качества.

\subsection{Метрики качества}
Для оценки качества используются precision, recall, FPR и агрегированные показатели. Формулы:
\[
Precision = \frac{TP}{TP + FP}, \quad Recall = \frac{TP}{TP + FN}, \quad FPR = \frac{FP}{FP + TN}.
\]
В учебном проекте приоритет отдаётся полноте (Recall), чтобы не пропустить подозрительные события.

\subsection{KPI и операционные метрики}
В дополнение к модельным метрикам используются операционные показатели, которые удобны для дашбордов и презентаций (таблица~\ref{tab:kpi}).

\begin{longtable}{|L{5.2cm}|L{9.2cm}|}
\hline
\textbf{Показатель} & \textbf{Интерпретация} \\ \hline
\endfirsthead
\hline
\textbf{Показатель} & \textbf{Интерпретация} \\ \hline
\endhead
Доля аномалий & Отражает интенсивность подозрительной активности. \\ \hline
Время от события до алерта & Важный показатель оперативности. \\ \hline
Объём обработанных событий & Характеризует нагрузку и масштаб. \\ \hline
Стабильность модели & Число переобучений и дрейф показателей. \\ \hline
Точность первичного отбора & Соотношение подтверждённых инцидентов и алертов. \\ \hline
\caption{Операционные метрики и KPI}
\label{tab:kpi}
\end{longtable}

\subsection{Интерфейсы и интеграции}
API предоставляет endpoints:
\begin{itemize}
    \item /ingest --- приём логов и запуск детекции.
    \item /anomalies --- выборка аномалий.
    \item /metrics --- агрегированные метрики.
    \item /health --- проверка состояния сервиса.
\end{itemize}
Экспорт для дашборда реализован через базу данных и JSON-метрики: Grafana подключается к PostgreSQL и визуализирует агрегаты по временным окнам. Такой подход позволяет использовать стандартные панели без разработки отдельного UI.

\subsection{Как система повышает защищённость}
Система не блокирует атаки напрямую, но повышает защищённость за счёт раннего выявления подозрительных событий и снижения времени реакции. При ограниченных ресурсах аналитиков безопасности это даёт приоритет для расследований и позволяет быстрее локализовать угрозу.

\begin{figure}[h]
    \centering
\includesvg[width=0.9\textwidth]{defense_loop}
    \caption{Цикл повышения защищённости через мониторинг и аналитику}
\end{figure}

Детекция основана на выявлении нетипичного поведения: редких шаблонов, необычных сочетаний признаков и аномальных временных паттернов. Это помогает обнаруживать инциденты, не описанные заранее правилами, и дополняет корреляционные механизмы SIEM. В терминах MITRE ATT\&CK система поддерживает выявление аномальных действий на этапах initial access, credential access, execution и exfiltration, когда изменение логов заметно по статистике или паттернам\cite{mitre}.

Практически это означает, что система выявляет «слабые» сигналы, которые теряются в шуме: редкие шаблоны ошибок, неожиданные IP-адреса, появление новых типов запросов или нетипичные временные всплески. За счёт нормализации и скоринга поток логов превращается в компактный список кандидатов на расследование.

Ключевые механизмы повышения защищённости:
\begin{itemize}
    \item сжатие потока до управляемого списка событий с высоким score;
    \item раннее оповещение о новых и редких шаблонах сообщений;
    \item приоритизация инцидентов по риску и контексту;
    \item фиксация версии модели и артефактов для воспроизводимого разбора.
\end{itemize}

Система поддерживает операционный цикл реагирования: событие с высоким score поступает в хранилище, где к нему можно применить фильтры, сопоставить с другими инцидентами и связать с таймлайном. Это позволяет аналитикам быстрее принять решение о блокировке, изоляции или дополнительной проверке.

После фиксации аномалии результат сохраняется вместе с исходным событием, что облегчает дальнейший разбор: аналитик получает контекст, метки и привязку к версии модели, а также тренды в дашборде для оценки масштаба проблемы.

\subsection{Безопасность и устойчивость}
Для демонстрационного сценария реализовано логирование в формате JSON и изоляция компонентов через Docker. В продуктивных системах необходимо дополнительно учитывать контроль доступа к API, ограничение нагрузки, защиту от подмены логов и журналирование действий операторов. Рекомендации по контролям безопасности и применению систем обнаружения вторжений подчёркивают важность качества данных и корректной интерпретации аномалий\cite{nist_sp80053,nist_idps}.

\subsection{Выбор технологий}
Python выбран за богатую ML-экосистему и доступность библиотек. FastAPI обеспечивает быстрый REST-интерфейс, SQLAlchemy --- абстракцию базы данных, Docker Compose --- воспроизводимость запуска, а Grafana --- визуализацию метрик и аномалий. Такой стек позволяет быстро собрать рабочий прототип и масштабировать решение при необходимости.

\section{Реализация и результаты}

\subsection{Генератор синтетических логов}
Для демонстрации реализован генератор, который создаёт нормальный поток и контролируемый набор аномалий. В аномалиях повышается уровень критичности, изменяются IP-адреса и сообщения. Такой подход позволяет тестировать детектор в контролируемой среде и изменять долю аномалий.

\subsection{Модель данных и хранение}
В базе фиксируются исходные поля логов, вычисленные scores и метаданные модели. Это обеспечивает трассировку принятого решения и возможность ретроспективного анализа. Основные поля представлены в таблице~\ref{tab:schema}.

\begin{longtable}{|L{4.5cm}|L{9.5cm}|}
\hline
\textbf{Поле} & \textbf{Описание} \\ \hline
\endfirsthead
\hline
\textbf{Поле} & \textbf{Описание} \\ \hline
\endhead
Timestamp & Время события в UTC. \\ \hline
Host или Service & Источник события (узел или сервис). \\ \hline
Level & Уровень логирования. \\ \hline
Message & Текст сообщения. \\ \hline
User, IP, Request\_ID & Опциональные атрибуты контекста. \\ \hline
Anomaly\_Score & Нормализованная оценка аномальности. \\ \hline
Is\_Anomaly & Итоговая метка (normal или anomaly). \\ \hline
Model\_Version & Версия и тип модели. \\ \hline
\caption{Схема хранения событий}
\label{tab:schema}
\end{longtable}

\subsection{Визуализация и метрики}
Дашборд отображает общее число событий, долю аномалий и временные тренды. В Grafana предусмотрены панели для временного ряда аномалий и агрегированных показателей. Для иллюстраций использованы открытые иконки Heroicons и Tabler Icons\cite{heroicons,tablericons}.

\begin{figure}[h]
    \centering
\includesvg[width=0.9\textwidth]{metrics}
    \caption{Схема формирования метрик и дашбордов}
\end{figure}

\subsection{Набор экспериментальных сценариев}
Для демонстрации качества и устойчивости предусмотрены сценарии:
\begin{itemize}
    \item нормальный поток без аномалий для обучения и базовой валидации;
    \item поток с инъекцией редких шаблонов сообщений и IP-адресов;
    \item всплеск ошибок после релиза (5xx и таймауты);
    \item временные «окна» аномальной активности (ночные пики);
    \item имитация дрейфа: постепенное изменение распределений событий.
\end{itemize}

\subsection{Экспериментальная оценка}
На синтетических данных проведён подбор порогов для двух методов. Базовый частотный метод показывает высокую полноту при правильно выбранном пороге, а Isolation Forest даёт баланс между precision и recall. В демонстрационном режиме приоритет отдаётся полноте, чтобы не пропустить потенциально опасные события.

\subsection{Иллюстративные результаты на синтетике}
В таблице~\ref{tab:results} приведены ориентировочные результаты на синтетических данных (для сравнения подходов, без претензии на промышленную точность).

\begin{longtable}{|L{4.5cm}|L{3.5cm}|L{3.5cm}|L{3.5cm}|}
\hline
\textbf{Метод} & \textbf{Precision} & \textbf{Recall} & \textbf{FPR} \\ \hline
\endfirsthead
\hline
\textbf{Метод} & \textbf{Precision} & \textbf{Recall} & \textbf{FPR} \\ \hline
\endhead
Базовый частотный & 0.62 & 0.93 & 0.08 \\ \hline
Isolation Forest & 0.78 & 0.88 & 0.05 \\ \hline
\caption{Ориентировочные результаты на синтетике}
\label{tab:results}
\end{longtable}

\subsection{Кейсы, где система могла бы помочь}
Ниже приведены примеры сценариев, в которых детектор аномалий в логах может дать ранний сигнал и помочь аналитикам:
\begin{enumerate}
    \item \textbf{Brute-force аутентификация.} Серия неудачных попыток входа с одного IP или пользователя вызывает рост доли сообщений с ключевыми словами failed/denied, что фиксируется как аномалия.
    \item \textbf{Credential stuffing.} Массовые попытки входа в разные сервисы от одного источника приводят к атипичной последовательности событий и отклонениям по временным признакам.
    \item \textbf{Повышение привилегий.} Появление редких сообщений о sudo/root, нетипичные уровни логов и новые шаблоны сообщений формируют высокий anomaly score.
    \item \textbf{Латеральное перемещение.} Один и тот же пользователь начинает обращаться к множеству хостов или сервисов, что меняет распределение по источникам и коррелирующим признакам.
    \item \textbf{Экфильтрация данных.} В логах фиксируются нетипичные внешние IP-адреса, а также нестандартные размеры сообщений и временные пики активности.
    \item \textbf{Эксплуатация уязвимости приложения.} Резкое появление новых шаблонов ошибок или частые 5xx-коды после релиза сигнализируют о возможной атаке или дефекте.
    \item \textbf{Вредоносная активность на сервере.} Сервисы начинают аварийно завершаться, растёт число CRITICAL/ALERT событий, что детектируется как аномалия.
    \item \textbf{Внутренние злоупотребления.} Необычные паттерны доступа к данным в ночное время или резкий рост запросов от отдельных аккаунтов фиксируются системой.
\end{enumerate}

\subsection{Сценарий демонстрации}
Демонстрация включает следующие шаги:
\begin{enumerate}
    \item Сгенерировать нормальные логи и обучить модель.
    \item Запустить API и отправить смешанный поток с аномалиями.
    \item Проверить /anomalies и /metrics.
    \item Просмотреть динамику в дашборде.
\end{enumerate}

\subsection{Тестирование и CI/CD}
Проект содержит тесты для парсеров, извлечения признаков, моделей и API. В CI-процессе выполняются линтеры и тесты. Артефакты модели сохраняются в директории artifacts и могут быть использованы для повторного запуска без переобучения.

\section{Оценка эффективности и перспективы развития}

\subsection{Эффективность решения}
Учебный проект позволяет воспроизводимо продемонстрировать методы обнаружения аномалий и обеспечить прозрачность решений. За счёт упрощённых признаков время обучения минимально, что важно в образовательных сценариях. В перспективе возможно расширение признаков и подключение реальных источников логов.

С точки зрения практической ценности проект иллюстрирует, как требования нормативных документов и отраслевых рекомендаций трансформируются в архитектуру и конкретные реализации: обязательные поля, единые схемы, базовые метрики и воспроизводимость.

\subsection{Перспективы развития}
Возможные направления развития:
\begin{itemize}
    \item интеграция со стриминговыми источниками (Kafka, Redis Streams);
    \item использование эмбеддингов текста и автоэнкодеров, как в исследовательских работах\cite{loganomaly,logbert};
    \item введение контекстной корреляции между событиями и ATT\&CK-тактиками\cite{mitre};
    \item расширение наборов метрик и алертинга.
\end{itemize}

\subsection{План внедрения (презентационный формат)}
Последовательность шагов внедрения для учебного стенда:
\begin{enumerate}
    \item Подготовка окружения и запуск контейнеров (API, БД, Grafana).
    \item Загрузка нормального потока логов и обучение модели.
    \item Проверка качества данных и корректности извлечения признаков.
    \item Запуск смешанного потока и анализ результатов детекции.
    \item Настройка порогов и финальная демонстрация.
\end{enumerate}

\subsection{Риски и меры}
Основные риски и способы их снижения приведены в таблице~\ref{tab:risks}.

\begin{longtable}{|L{5.5cm}|L{8.5cm}|}
\hline
\textbf{Риск} & \textbf{Мера} \\ \hline
\endfirsthead
\hline
\textbf{Риск} & \textbf{Мера} \\ \hline
\endhead
Низкое качество входных логов & Валидация полей, фильтрация некорректных строк. \\ \hline
Сильный концепт-дрифт & Периодическое переобучение и версия модели. \\ \hline
Избыточные ложные срабатывания & Настройка порога, калибровка по синтетике. \\ \hline
Недостаток интерпретируемости & Базовый метод и прозрачные признаки. \\ \hline
Сложность демонстрации & Готовый генератор и сценарий демо. \\ \hline
\caption{Риски и меры}
\label{tab:risks}
\end{longtable}

\section{Допущения и ограничения}
\begin{itemize}
    \item Обучение выполняется на заранее подготовленном «нормальном» потоке логов.
    \item Признаки упрощены и предназначены для демонстрации метода, а не промышленного детекта.
    \item Интеграции со стриминговыми системами заданы как интерфейсы-заглушки.
    \item Для сложных инфраструктур требуется дополнительная калибровка порогов.
\end{itemize}

\addcontentsline{toc}{section}{Заключение}
\section*{Заключение}
Разработан учебный анализатор логов на основе ИИ, демонстрирующий полный цикл: генерация данных, обучение, обнаружение аномалий и визуализация. Проект обеспечивает воспроизводимость и расширяемость, что делает его полезным для обучения и демонстраций в задачах мониторинга и реагирования.

\addcontentsline{toc}{section}{Список использованных источников}
\begin{thebibliography}{22}
    \bibitem{verizon} Verizon. Data Breach Investigations Report 2025.\,---\,URL: \url{https://www.verizon.com/business/resources/reports/dbir/} (дата обращения: 04.01.2026).
    \bibitem{mandiant} Mandiant. M-Trends 2024.\,---\,URL: \url{https://www.mandiant.com/resources/m-trends} (дата обращения: 04.01.2026).
    \bibitem{nistlog} Kent K., Souppaya M. Guide to Computer Security Log Management (NIST SP 800-92).\,---\,Gaithersburg: NIST, 2006.\,---\,URL: \url{https://csrc.nist.gov/publications/detail/sp/800-92/final} (дата обращения: 04.01.2026).
    \bibitem{nist_iscm} Dempsey K., Ross R. Information Security Continuous Monitoring (ISCM) for Federal Information Systems and Organizations (NIST SP 800-137).\,---\,Gaithersburg: NIST, 2011.\,---\,URL: \url{https://csrc.nist.gov/publications/detail/sp/800-137/final} (дата обращения: 04.01.2026).
    \bibitem{nist_idps} Scarfone K., Mell P. Guide to Intrusion Detection and Prevention Systems (IDPS) (NIST SP 800-94).\,---\,Gaithersburg: NIST, 2007.\,---\,URL: \url{https://csrc.nist.gov/publications/detail/sp/800-94/final} (дата обращения: 04.01.2026).
    \bibitem{nist_sp80053} NIST. Security and Privacy Controls for Information Systems and Organizations (NIST SP 800-53 Rev. 5).\,---\,URL: \url{https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final} (дата обращения: 04.01.2026).
    \bibitem{nist_csf} NIST. Cybersecurity Framework 2.0.\,---\,URL: \url{https://www.nist.gov/cyberframework} (дата обращения: 04.01.2026).
    \bibitem{enisa} ENISA. Threat Landscape 2024.\,---\,URL: \url{https://www.enisa.europa.eu/publications/enisa-threat-landscape-2024} (дата обращения: 04.01.2026).
    \bibitem{mitre} MITRE ATT\&CK Knowledge Base.\,---\,URL: \url{https://attack.mitre.org/} (дата обращения: 04.01.2026).
    \bibitem{owasp_logging} OWASP Logging Cheat Sheet.\,---\,URL: \url{https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html} (дата обращения: 04.01.2026).
    \bibitem{cisa_logging} CISA. Logging Made Easy.\,---\,URL: \url{https://www.cisa.gov/resources-tools/services/logging-made-easy} (дата обращения: 04.01.2026).
    \bibitem{cis_controls} CIS Critical Security Controls.\,---\,URL: \url{https://www.cisecurity.org/controls} (дата обращения: 04.01.2026).
    \bibitem{ecs} Elastic Common Schema (ECS) Reference.\,---\,URL: \url{https://www.elastic.co/guide/en/ecs/current/index.html} (дата обращения: 04.01.2026).
    \bibitem{otel_logs} OpenTelemetry Logging Specification.\,---\,URL: \url{https://opentelemetry.io/docs/specs/otel/logs/} (дата обращения: 04.01.2026).
    \bibitem{logbench} He P., Zhu J., Zheng Z., Lyu M. Tools and Benchmarks for Automated Log Parsing.\,---\,arXiv:1811.03509.\,---\,URL: \url{https://arxiv.org/abs/1811.03509} (дата обращения: 04.01.2026).
    \bibitem{loglizer} LogPAI. Loglizer: A log analysis toolkit.\,---\,URL: \url{https://github.com/logpai/loglizer} (дата обращения: 04.01.2026).
    \bibitem{loganomaly} Meng W., Liu Y., Zhu Y., Zhang S., Pei D., Yuan H., Liu Y. LogAnomaly: Unsupervised Detection of Sequential and Quantitative Anomalies in Unstructured Logs.\,---\,IJCAI 2019.\,---\,URL: \url{https://www.ijcai.org/proceedings/2019/0661.pdf} (дата обращения: 04.01.2026).
    \bibitem{logbert} Guo H., Yuan L., Wang Y., Chen Q., Zhang H., Liu Y. LogBERT: Log Anomaly Detection via BERT.\,---\,arXiv:2103.04475.\,---\,URL: \url{https://arxiv.org/abs/2103.04475} (дата обращения: 04.01.2026).
    \bibitem{fastapi} FastAPI Documentation.\,---\,URL: \url{https://fastapi.tiangolo.com/} (дата обращения: 04.01.2026).
    \bibitem{grafana} Grafana Documentation.\,---\,URL: \url{https://grafana.com/docs/} (дата обращения: 04.01.2026).
    \bibitem{heroicons} Heroicons by Tailwind Labs (MIT License).\,---\,URL: \url{https://heroicons.com/} (дата обращения: 04.01.2026).
    \bibitem{tablericons} Tabler Icons (MIT License).\,---\,URL: \url{https://tabler.io/icons} (дата обращения: 04.01.2026).
\end{thebibliography}

\end{document}
